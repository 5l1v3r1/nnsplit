{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(\"python_lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import nnsplit\n",
    "from nnsplit import train, utils, models\n",
    "train.tqdm = tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = Path(\"cache\")\n",
    "cache_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train.prepare_data(\"train_data/dewiki-20180920-corpus.xml\", \"de\", max_n_sentences=10_000_000, \n",
    "                       data_directory=cache_dir / \"de_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train.prepare_data(\"train_data/enwiki-20181001-corpus.xml\", \"en\", max_n_sentences=10_000_000, \n",
    "                       data_directory=cache_dir / \"en_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model (german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load(cache_dir / \"de_data/all_sentences.pt\")\n",
    "y = torch.load(cache_dir / \"de_data/all_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.1, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.034266</td>\n",
       "      <td>0.036270</td>\n",
       "      <td>17:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.028387</td>\n",
       "      <td>0.027380</td>\n",
       "      <td>17:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.025026</td>\n",
       "      <td>0.026409</td>\n",
       "      <td>17:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>17:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023266</td>\n",
       "      <td>0.024745</td>\n",
       "      <td>17:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>0.024190</td>\n",
       "      <td>17:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.023747</td>\n",
       "      <td>0.023252</td>\n",
       "      <td>17:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>0.022639</td>\n",
       "      <td>17:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.021643</td>\n",
       "      <td>0.022049</td>\n",
       "      <td>17:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.022001</td>\n",
       "      <td>0.021097</td>\n",
       "      <td>17:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>17:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.018794</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>17:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.017931</td>\n",
       "      <td>0.018451</td>\n",
       "      <td>17:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.015812</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>17:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.016664</td>\n",
       "      <td>0.017853</td>\n",
       "      <td>17:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "de_model = train.train(x_train, y_train, x_valid, y_valid, n_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(de_model, Path(\"cache/de_data\") / \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bminixhofer/miniconda3/lib/python3.7/site-packages/tensorflowjs/converters/keras_h5_conversion.py:122: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  return h5py.File(h5file)\n"
     ]
    }
   ],
   "source": [
    "utils.store_model(de_model, \"data/de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_model = torch.load(Path(\"cache/de_data\") / \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f6eff8d54045e787eb1734644db616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target: Tokenize \n",
      "\n",
      "F1: 0.9985709185426798\n",
      "Precision: 0.9977352694599613\n",
      "Recall: 0.9994079685876922\n",
      "\n",
      "\n",
      "\n",
      "Target: Sentencize \n",
      "\n",
      "F1: 0.9581387972891665\n",
      "Precision: 0.9362705478411474\n",
      "Recall: 0.9810530203414978\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.evaluate(de_model.cuda().half(), x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.quantize_dynamic(de_model.float().cpu(), {nn.LSTM, nn.Linear}, dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e110baec60f442c5afd934a8d22af664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target: Tokenize \n",
      "\n",
      "F1: 0.9985806618134485\n",
      "Precision: 0.9977847594261771\n",
      "Recall: 0.9993778349483429\n",
      "\n",
      "\n",
      "\n",
      "Target: Sentencize \n",
      "\n",
      "F1: 0.9581120292762628\n",
      "Precision: 0.9363237215520647\n",
      "Recall: 0.9809385261100492\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.evaluate(quantized_model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model (english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load(cache_dir / \"en_data/all_sentences.pt\")\n",
    "y = torch.load(cache_dir / \"en_data/all_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.1, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.045592</td>\n",
       "      <td>0.045185</td>\n",
       "      <td>18:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.037289</td>\n",
       "      <td>0.036578</td>\n",
       "      <td>18:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.037222</td>\n",
       "      <td>0.035395</td>\n",
       "      <td>18:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>0.034768</td>\n",
       "      <td>18:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032515</td>\n",
       "      <td>0.034059</td>\n",
       "      <td>18:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.033148</td>\n",
       "      <td>18:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.032019</td>\n",
       "      <td>18:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.030080</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>18:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>0.030739</td>\n",
       "      <td>18:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>0.029577</td>\n",
       "      <td>18:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.027141</td>\n",
       "      <td>0.028753</td>\n",
       "      <td>18:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.026856</td>\n",
       "      <td>0.027485</td>\n",
       "      <td>18:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.026406</td>\n",
       "      <td>0.026662</td>\n",
       "      <td>18:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.026053</td>\n",
       "      <td>0.026149</td>\n",
       "      <td>18:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.024190</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>18:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_model = train.train(x_train, y_train, x_valid, y_valid, n_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(en_model, Path(\"cache/en_data\") / \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.store_model(en_model, \"data/en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ccabd62f6947808529fbb564f25d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 156.00 MiB (GPU 0; 10.75 GiB total capacity; 64.64 MiB already allocated; 155.31 MiB free; 76.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-db49040a7d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/nnsplit/python_lib/nnsplit/train.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, sentences_valid, labels_valid, threshold, batch_size)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/nnsplit/python_lib/nnsplit/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 559\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 156.00 MiB (GPU 0; 10.75 GiB total capacity; 64.64 MiB already allocated; 155.31 MiB free; 76.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "train.evaluate(en_model.cuda().half(), x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsplit import NNSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = NNSplit(utils.load_model(\"data/de\").float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter.split([\"Das ist ein Test Das ist noch ein Test.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = NNSplit(utils.load_model(\"data/en\").float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter.split([\"He is making test, exercises etc. and examples. This is another test.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1_000_000\n",
    "x = torch.load(cache_dir / \"de_data/all_sentences.pt\")[:n]\n",
    "y = torch.load(cache_dir / \"de_data/all_labels.pt\")[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.035032</td>\n",
       "      <td>0.035142</td>\n",
       "      <td>01:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train.train(x_train, y_train, x_valid, y_valid, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>01:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train.train(x_train, y_train, x_valid, y_valid, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.quantize_dynamic(model.float().cpu(), {nn.LSTM, nn.Linear}, dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/98 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/98 [00:00<01:09,  1.41it/s]\u001b[A\n",
      "  2%|▏         | 2/98 [00:01<01:09,  1.39it/s]\u001b[A\n",
      "  3%|▎         | 3/98 [00:02<01:12,  1.32it/s]\u001b[A\n",
      "  4%|▍         | 4/98 [00:03<01:22,  1.14it/s]\u001b[A\n",
      "  5%|▌         | 5/98 [00:04<01:28,  1.06it/s]\u001b[A\n",
      "  6%|▌         | 6/98 [00:05<01:19,  1.16it/s]\u001b[A\n",
      "  7%|▋         | 7/98 [00:06<01:28,  1.03it/s]\u001b[A\n",
      "  8%|▊         | 8/98 [00:07<01:27,  1.03it/s]\u001b[A\n",
      "  9%|▉         | 9/98 [00:08<01:25,  1.04it/s]\u001b[A\n",
      " 10%|█         | 10/98 [00:09<01:27,  1.01it/s]\u001b[A\n",
      " 11%|█         | 11/98 [00:10<01:24,  1.03it/s]\u001b[A\n",
      " 12%|█▏        | 12/98 [00:11<01:19,  1.09it/s]\u001b[A\n",
      " 13%|█▎        | 13/98 [00:12<01:17,  1.10it/s]\u001b[A\n",
      " 14%|█▍        | 14/98 [00:13<01:23,  1.01it/s]\u001b[A\n",
      " 15%|█▌        | 15/98 [00:14<01:23,  1.00s/it]\u001b[A\n",
      " 16%|█▋        | 16/98 [00:15<01:28,  1.08s/it]\u001b[A\n",
      " 17%|█▋        | 17/98 [00:16<01:23,  1.03s/it]\u001b[A\n",
      " 18%|█▊        | 18/98 [00:17<01:23,  1.04s/it]\u001b[A\n",
      " 19%|█▉        | 19/98 [00:18<01:25,  1.08s/it]\u001b[A\n",
      " 20%|██        | 20/98 [00:19<01:23,  1.07s/it]\u001b[A\n",
      " 21%|██▏       | 21/98 [00:20<01:16,  1.01it/s]\u001b[A\n",
      " 22%|██▏       | 22/98 [00:21<01:18,  1.03s/it]\u001b[A\n",
      " 23%|██▎       | 23/98 [00:22<01:11,  1.05it/s]\u001b[A\n",
      " 24%|██▍       | 24/98 [00:23<01:13,  1.01it/s]\u001b[A\n",
      " 26%|██▌       | 25/98 [00:24<01:06,  1.10it/s]\u001b[A\n",
      " 27%|██▋       | 26/98 [00:25<01:04,  1.11it/s]\u001b[A\n",
      " 28%|██▊       | 27/98 [00:26<01:05,  1.08it/s]\u001b[A\n",
      " 29%|██▊       | 28/98 [00:26<01:02,  1.12it/s]\u001b[A\n",
      " 30%|██▉       | 29/98 [00:27<01:03,  1.09it/s]\u001b[A\n",
      " 31%|███       | 30/98 [00:28<01:04,  1.05it/s]\u001b[A\n",
      " 32%|███▏      | 31/98 [00:29<01:06,  1.00it/s]\u001b[A\n",
      " 33%|███▎      | 32/98 [00:30<01:00,  1.09it/s]\u001b[A\n",
      " 34%|███▎      | 33/98 [00:31<01:04,  1.01it/s]\u001b[A\n",
      " 35%|███▍      | 34/98 [00:33<01:12,  1.13s/it]\u001b[A\n",
      " 36%|███▌      | 35/98 [00:34<01:11,  1.14s/it]\u001b[A\n",
      " 37%|███▋      | 36/98 [00:35<01:05,  1.06s/it]\u001b[A\n",
      " 38%|███▊      | 37/98 [00:36<00:58,  1.05it/s]\u001b[A\n",
      " 39%|███▉      | 38/98 [00:36<00:54,  1.11it/s]\u001b[A\n",
      " 40%|███▉      | 39/98 [00:37<00:48,  1.21it/s]\u001b[A\n",
      " 41%|████      | 40/98 [00:38<00:49,  1.18it/s]\u001b[A\n",
      " 42%|████▏     | 41/98 [00:39<00:44,  1.28it/s]\u001b[A\n",
      " 43%|████▎     | 42/98 [00:39<00:43,  1.29it/s]\u001b[A\n",
      " 44%|████▍     | 43/98 [00:40<00:45,  1.21it/s]\u001b[A\n",
      " 45%|████▍     | 44/98 [00:41<00:43,  1.25it/s]\u001b[A\n",
      " 46%|████▌     | 45/98 [00:42<00:41,  1.27it/s]\u001b[A\n",
      " 47%|████▋     | 46/98 [00:43<00:41,  1.24it/s]\u001b[A\n",
      " 48%|████▊     | 47/98 [00:43<00:40,  1.25it/s]\u001b[A\n",
      " 49%|████▉     | 48/98 [00:44<00:39,  1.28it/s]\u001b[A\n",
      " 50%|█████     | 49/98 [00:45<00:38,  1.26it/s]\u001b[A\n",
      " 51%|█████     | 50/98 [00:46<00:39,  1.22it/s]\u001b[A\n",
      " 52%|█████▏    | 51/98 [00:46<00:35,  1.31it/s]\u001b[A\n",
      " 53%|█████▎    | 52/98 [00:48<00:49,  1.07s/it]\u001b[A\n",
      " 54%|█████▍    | 53/98 [00:49<00:45,  1.01s/it]\u001b[A\n",
      " 55%|█████▌    | 54/98 [00:50<00:43,  1.00it/s]\u001b[A\n",
      " 56%|█████▌    | 55/98 [00:51<00:40,  1.06it/s]\u001b[A\n",
      " 57%|█████▋    | 56/98 [00:52<00:36,  1.14it/s]\u001b[A\n",
      " 58%|█████▊    | 57/98 [00:52<00:33,  1.22it/s]\u001b[A\n",
      " 59%|█████▉    | 58/98 [00:53<00:32,  1.23it/s]\u001b[A\n",
      " 60%|██████    | 59/98 [00:54<00:32,  1.20it/s]\u001b[A\n",
      " 61%|██████    | 60/98 [00:55<00:31,  1.20it/s]\u001b[A\n",
      " 62%|██████▏   | 61/98 [00:55<00:29,  1.26it/s]\u001b[A\n",
      " 63%|██████▎   | 62/98 [00:57<00:31,  1.14it/s]\u001b[A\n",
      " 64%|██████▍   | 63/98 [00:58<00:31,  1.11it/s]\u001b[A\n",
      " 65%|██████▌   | 64/98 [00:58<00:28,  1.19it/s]\u001b[A\n",
      " 66%|██████▋   | 65/98 [00:59<00:26,  1.24it/s]\u001b[A\n",
      " 67%|██████▋   | 66/98 [01:00<00:25,  1.27it/s]\u001b[A\n",
      " 68%|██████▊   | 67/98 [01:00<00:23,  1.33it/s]\u001b[A\n",
      " 69%|██████▉   | 68/98 [01:01<00:21,  1.38it/s]\u001b[A\n",
      " 70%|███████   | 69/98 [01:02<00:21,  1.36it/s]\u001b[A\n",
      " 71%|███████▏  | 70/98 [01:03<00:21,  1.30it/s]\u001b[A\n",
      " 72%|███████▏  | 71/98 [01:03<00:20,  1.29it/s]\u001b[A\n",
      " 73%|███████▎  | 72/98 [01:04<00:20,  1.29it/s]\u001b[A\n",
      " 74%|███████▍  | 73/98 [01:05<00:19,  1.28it/s]\u001b[A\n",
      " 76%|███████▌  | 74/98 [01:06<00:18,  1.32it/s]\u001b[A\n",
      " 77%|███████▋  | 75/98 [01:06<00:17,  1.32it/s]\u001b[A\n",
      " 78%|███████▊  | 76/98 [01:07<00:16,  1.34it/s]\u001b[A\n",
      " 79%|███████▊  | 77/98 [01:08<00:15,  1.39it/s]\u001b[A\n",
      " 80%|███████▉  | 78/98 [01:09<00:14,  1.36it/s]\u001b[A\n",
      " 81%|████████  | 79/98 [01:09<00:14,  1.31it/s]\u001b[A\n",
      " 82%|████████▏ | 80/98 [01:10<00:13,  1.35it/s]\u001b[A\n",
      " 83%|████████▎ | 81/98 [01:11<00:12,  1.31it/s]\u001b[A\n",
      " 84%|████████▎ | 82/98 [01:12<00:13,  1.18it/s]\u001b[A\n",
      " 85%|████████▍ | 83/98 [01:13<00:12,  1.16it/s]\u001b[A\n",
      " 86%|████████▌ | 84/98 [01:14<00:12,  1.13it/s]\u001b[A\n",
      " 87%|████████▋ | 85/98 [01:15<00:11,  1.16it/s]\u001b[A\n",
      " 88%|████████▊ | 86/98 [01:15<00:09,  1.20it/s]\u001b[A\n",
      " 89%|████████▉ | 87/98 [01:16<00:08,  1.24it/s]\u001b[A\n",
      " 90%|████████▉ | 88/98 [01:17<00:07,  1.30it/s]\u001b[A\n",
      " 91%|█████████ | 89/98 [01:18<00:07,  1.27it/s]\u001b[A\n",
      " 92%|█████████▏| 90/98 [01:18<00:06,  1.30it/s]\u001b[A\n",
      " 93%|█████████▎| 91/98 [01:19<00:05,  1.22it/s]\u001b[A\n",
      " 94%|█████████▍| 92/98 [01:20<00:04,  1.27it/s]\u001b[A\n",
      " 95%|█████████▍| 93/98 [01:21<00:04,  1.22it/s]\u001b[A\n",
      " 96%|█████████▌| 94/98 [01:22<00:03,  1.14it/s]\u001b[A\n",
      " 97%|█████████▋| 95/98 [01:23<00:02,  1.18it/s]\u001b[A\n",
      " 98%|█████████▊| 96/98 [01:23<00:01,  1.20it/s]\u001b[A\n",
      " 99%|█████████▉| 97/98 [01:24<00:00,  1.27it/s]\u001b[A\n",
      "100%|██████████| 98/98 [01:25<00:00,  1.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Tokenize \n",
      "\n",
      "F1: 0.9982945732838129\n",
      "Precision: 0.9974475067007087\n",
      "Recall: 0.9991430798056675\n",
      "\n",
      "\n",
      "\n",
      "Target: Sentencize \n",
      "\n",
      "F1: 0.897711766558203\n",
      "Precision: 0.8391659852820932\n",
      "Recall: 0.9650393049234588\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.evaluate(quantized_model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/98 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 11/98 [00:00<00:00, 109.64it/s]\u001b[A\n",
      " 22%|██▏       | 22/98 [00:00<00:00, 107.66it/s]\u001b[A\n",
      " 35%|███▍      | 34/98 [00:00<00:00, 109.46it/s]\u001b[A\n",
      " 49%|████▉     | 48/98 [00:00<00:00, 116.24it/s]\u001b[A\n",
      " 63%|██████▎   | 62/98 [00:00<00:00, 120.74it/s]\u001b[A\n",
      " 77%|███████▋  | 75/98 [00:00<00:00, 121.12it/s]\u001b[A\n",
      "100%|██████████| 98/98 [00:00<00:00, 122.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Tokenize \n",
      "\n",
      "F1: 0.9973287289215611\n",
      "Precision: 0.9961537390852487\n",
      "Recall: 0.9985064938947623\n",
      "\n",
      "\n",
      "\n",
      "Target: Sentencize \n",
      "\n",
      "F1: 0.9055118110236221\n",
      "Precision: 0.8516719990905105\n",
      "Recall: 0.9666181268548045\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.evaluate(model.cuda().half(), x_valid, y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
